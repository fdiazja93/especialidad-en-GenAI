{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55532df",
   "metadata": {},
   "source": [
    "### 1. Laboratorio clase 3: Introducción y contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1201a947",
   "metadata": {},
   "source": [
    "En este laboratorio vamos a profundizar en la construcción de modelos N-gram, modelos de Markov ocultos, y en los principios de funcionamiento de redes neuronales en el contexto del procesamiento del lenguaje natural. El objetivo de estos ejercicios es aprende a construir modelos de lengiaje simples con los que podamos llevar a cabo tareas como completar prompts, asignarle tags a palabras y entrenar embedding para palabras usando redes neuronales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af491050",
   "metadata": {},
   "source": [
    "### 2. Modelos N-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaff1c1",
   "metadata": {},
   "source": [
    "En este ejercicio, vamos a construir modelos N-gram para completar texto. Para construir los modelos, vamos a permitir cambiar N para ver el desempeño del modelo con diferentes configuraciones. Adicionalmente, calcularemos las probabilidades que el modelo predice con suavizado de Laplace con el fin de mejorar el desempeño del modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "347c497b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/fdiazja/Documents/work/classes/especialidad-en-\n",
      "[nltk_data]     GenAI/Clase 3/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/fdiazja/Documents/work/classes/especialidad-en-\n",
      "[nltk_data]     GenAI/Clase 3/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /Users/fdiazja/Documents/work/classes/especialidad-en-\n",
      "[nltk_data]     GenAI/Clase 3/nltk_data...\n",
      "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /Users/fdiazja/Documents/work/classes/especialidad-en-\n",
      "[nltk_data]     GenAI/Clase 3/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n"
     ]
    }
   ],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import os\n",
    "import shutil\n",
    "local_nltk_path = os.path.join(os.getcwd(), \"nltk_data\")\n",
    "shutil.rmtree(local_nltk_path, ignore_errors=True)\n",
    "os.makedirs(local_nltk_path, exist_ok=True)\n",
    "import nltk\n",
    "nltk.data.path.clear()\n",
    "nltk.data.path.append(local_nltk_path)\n",
    "nltk.download('punkt', download_dir=local_nltk_path)\n",
    "nltk.download('punkt_tab', download_dir=local_nltk_path)\n",
    "nltk.download('perluniprops', download_dir=local_nltk_path)\n",
    "nltk.download('nonbreaking_prefixes', download_dir=local_nltk_path)\n",
    "from collections import Counter\n",
    "import math\n",
    "import unicodedata\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb5f5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el corpus de texto en español para entrenar el modelo. Además, procesamos el texto para eliminar acentos y normalizarlo.\n",
    "\n",
    "corpus = \"\"\"\n",
    "El gato se sentó en la alfombra. El perro se sentó en el tronco. El gato y el perro son amigos.\n",
    "María tiene un gato llamado Tomás que le gusta dormir en la alfombra.\n",
    "Los perros generalmente prefieren los espacios abiertos como los parques.\n",
    "Ana y Juan pasean a sus perros todas las mañanas antes del desayuno.\n",
    "El clima estaba soleado y los niños jugaban con sus mascotas en el jardín.\n",
    "Un gato curioso se subió al tejado y observó todo desde arriba.\n",
    "La tienda de mascotas vende comida, juguetes y ropa para perros y gatos.\n",
    "\"\"\"\n",
    "\n",
    "def normalize_text(text, remove_punctuation=False):\n",
    "    \"\"\"\n",
    "    Normaliza el texto eliminando acentos y, opcionalmente, signos de puntuación.\n",
    "\n",
    "    Args:\n",
    "        text (str): Texto de entrada a normalizar.\n",
    "        remove_punctuation (bool): Si es True, elimina la puntuación.\n",
    "\n",
    "    Returns:\n",
    "        str: Texto normalizado.\n",
    "    \"\"\"\n",
    "    text = ''.join(c for c in unicodedata.normalize('NFD', text)\n",
    "                   if unicodedata.category(c) != 'Mn')\n",
    "    if remove_punctuation:\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text\n",
    "\n",
    "\n",
    "cleaned_corpus = normalize_text(corpus, remove_punctuation=False)\n",
    "tokens = nltk.word_tokenize(cleaned_corpus.lower(), language='spanish')\n",
    "vocab = set(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265a4f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos N-gramas y calculamos probabilidades suavizadas.\n",
    "\n",
    "def generate_ngrams(tokens, N):\n",
    "    \"\"\"\n",
    "    Genera una lista de N-gramas a partir de una lista de tokens.\n",
    "\n",
    "    Args:\n",
    "        tokens (list): Lista de tokens (palabras).\n",
    "        N (int): Tamaño del N-grama.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de tuplas, cada una representando un N-grama.\n",
    "    \"\"\"\n",
    "    return [tuple(tokens[i:i+N]) for i in range(len(tokens)-N+1)]\n",
    "\n",
    "N = 1\n",
    "grams = generate_ngrams(tokens, N)\n",
    "ngram_freq = Counter(grams)\n",
    "prefix_freq = Counter([gram[:-1] for gram in grams])\n",
    "\n",
    "def ngram_prob_smoothed(prefix, word, alpha=0.3):\n",
    "    \"\"\"\n",
    "    Calcula la probabilidad suavizada (Laplace) de que una palabra siga a un prefijo dado.\n",
    "\n",
    "    Args:\n",
    "        prefix (tuple or list): Prefijo de palabras (N-1 palabras).\n",
    "        word (str): Palabra candidata a seguir el prefijo.\n",
    "        alpha (float): Parámetro de suavizado.\n",
    "\n",
    "    Returns:\n",
    "        float: Probabilidad suavizada de la palabra dada el prefijo.\n",
    "    \"\"\"\n",
    "    prefix = tuple(prefix)\n",
    "    return (ngram_freq[prefix + (word,)] + alpha) / (prefix_freq[prefix] + alpha * len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abdff93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabra luego de ['el', ' ']: dormir\n"
     ]
    }
   ],
   "source": [
    "# Predicción de la siguiente palabra\n",
    "\n",
    "def predict_next_ngram(context):\n",
    "    \"\"\"\n",
    "    Predice la siguiente palabra más probable dado un contexto usando el modelo N-grama suavizado.\n",
    "\n",
    "    Args:\n",
    "        context (list): Lista de palabras previas (contexto).\n",
    "\n",
    "    Returns:\n",
    "        str: Palabra más probable como siguiente en el contexto.\n",
    "    \"\"\"\n",
    "    context = context[-(N-1):]  # ensure correct context length\n",
    "    candidates = {w: ngram_prob_smoothed(context, w) for w in vocab}\n",
    "    return max(candidates, key=candidates.get)\n",
    "\n",
    "print(f\"Palabra luego de ['el', 'gato']: {predict_next_ngram(['el', 'gato'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71377fa",
   "metadata": {},
   "source": [
    "### 3. POS usando modelos de Markov ocultos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a2f7fb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a2d8042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most likely POS tags: ['Articulo', 'Sustantivo', 'Verbo', 'Puntuacion', 'Articulo', 'Sustantivo', 'Verbo', 'Puntuacion', 'Articulo', 'Sustantivo', 'Verbo', 'Puntuacion']\n",
      "POS Prediction for new sentence:\n",
      "[('el', 'Articulo'), ('gato', 'Sustantivo'), ('juega', 'Verbo'), ('.', 'Puntuacion')]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Optional] To compare with SpaCy, install it and run: python -m spacy download es_core_news_sm\n"
     ]
    }
   ],
   "source": [
    "tagged_obs = [\n",
    "    ('el', 'Articulo'), ('gato', 'Sustantivo'), ('duerme', 'Verbo'), ('.', 'Puntuacion'),\n",
    "    ('la', 'Articulo'), ('niña', 'Sustantivo'), ('juega', 'Verbo'), ('.', 'Puntuacion'),\n",
    "    ('el', 'Articulo'), ('perro', 'Sustantivo'), ('ladra', 'Verbo'), ('.', 'Puntuacion')\n",
    "]\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# 1. Observations and states\n",
    "observations = [w for w, _ in tagged_obs]\n",
    "tags = [t for _, t in tagged_obs]\n",
    "states = sorted(set(tags))\n",
    "\n",
    "# 2. Compute start_prob (which tag starts a sentence?)\n",
    "# We'll assume new sentences start at positions: 0, 4, 8\n",
    "start_positions = [0, 4, 8]\n",
    "start_counts = Counter([tags[i] for i in start_positions])\n",
    "start_prob = {tag: start_counts[tag] / len(start_positions) for tag in states}\n",
    "\n",
    "# 3. Compute trans_prob (P(tag_i | tag_{i-1}))\n",
    "transitions = list(zip(tags[:-1], tags[1:]))\n",
    "trans_counts = Counter(transitions)\n",
    "prev_tag_counts = Counter(tags[:-1])\n",
    "trans_prob = {\n",
    "    tag1: {\n",
    "        tag2: trans_counts[(tag1, tag2)] / prev_tag_counts[tag1]\n",
    "        for tag2 in states if (tag1, tag2) in trans_counts\n",
    "    }\n",
    "    for tag1 in states\n",
    "}\n",
    "\n",
    "# 4. Compute emiss_prob (P(word | tag))\n",
    "emit_counts = defaultdict(Counter)\n",
    "for word, tag in tagged_obs:\n",
    "    emit_counts[tag][word] += 1\n",
    "\n",
    "emiss_prob = {\n",
    "    tag: {\n",
    "        word: count / sum(emit_counts[tag].values())\n",
    "        for word, count in emit_counts[tag].items()\n",
    "    }\n",
    "    for tag in states\n",
    "}\n",
    "\n",
    "\n",
    "def viterbi(obs, states, start_p, trans_p, emit_p):\n",
    "    \"\"\"\n",
    "    Implementa el algoritmo de Viterbi para encontrar la secuencia de etiquetas más probable en un modelo HMM.\n",
    "\n",
    "    Args:\n",
    "        obs (list): Secuencia de observaciones (palabras).\n",
    "        states (list): Lista de posibles estados (etiquetas).\n",
    "        start_p (dict): Probabilidades iniciales de los estados.\n",
    "        trans_p (dict): Probabilidades de transición entre estados.\n",
    "        emit_p (dict): Probabilidades de emisión de observaciones dado el estado.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (probabilidad total, lista de etiquetas más probables)\n",
    "    \"\"\"\n",
    "    V = [{}]\n",
    "    path = {}\n",
    "    for s in states:\n",
    "        start_prob_safe = start_p.get(s, 1e-6)\n",
    "        emit_prob_safe = emit_p.get(s, {}).get(obs[0], 1e-6)\n",
    "        V[0][s] = math.log(max(start_prob_safe, 1e-6)) + math.log(max(emit_prob_safe, 1e-6))\n",
    "        path[s] = [s]\n",
    "\n",
    "    for t in range(1, len(obs)):\n",
    "        V.append({})\n",
    "        new_path = {}\n",
    "        for curr in states:\n",
    "            (prob, prev) = max(\n",
    "                (\n",
    "                    V[t - 1][s] + math.log(trans_p[s].get(curr, 1e-6)) + math.log(emit_p[curr].get(obs[t], 1e-6)),\n",
    "                    s\n",
    "                ) for s in states\n",
    "            )\n",
    "            V[t][curr] = prob\n",
    "            new_path[curr] = path[prev] + [curr]\n",
    "        path = new_path\n",
    "\n",
    "    (prob, final_state) = max((V[-1][s], s) for s in states)\n",
    "    return math.exp(prob), path[final_state]\n",
    "\n",
    "prob, tags = viterbi(observations, states, start_prob, trans_prob, emiss_prob)\n",
    "print(\"Most likely POS tags:\", tags)\n",
    "\n",
    "def predict_pos(sentence):\n",
    "    \"\"\"\n",
    "    Predice la secuencia de etiquetas gramaticales (POS) para una oración dada usando un modelo HMM.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): Oración de entrada.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de tuplas (palabra, etiqueta).\n",
    "    \"\"\"\n",
    "    tokens = nltk.word_tokenize(sentence.lower(), language='spanish')\n",
    "    prob, tags = viterbi(tokens, states, start_prob, trans_prob, emiss_prob)\n",
    "    return list(zip(tokens, tags))\n",
    "\n",
    "# Example usage\n",
    "new_sentence = \"el gato juega .\"\n",
    "print(\"POS Prediction for new sentence:\")\n",
    "print(predict_pos(new_sentence))\n",
    "\n",
    "# Follow-up exercise: visualize tag distribution\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "pos_counts = Counter(tags)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x=list(pos_counts.keys()), y=list(pos_counts.values()))\n",
    "plt.title(\"POS Tag Distribution\")\n",
    "plt.xlabel(\"Tag\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: Compare with SpaCy POS tagging if installed\n",
    "try:\n",
    "    import spacy\n",
    "    nlp = spacy.load(\"es_core_news_sm\")\n",
    "    doc = nlp(\" \".join(observations))\n",
    "    spacy_tags = [token.pos_ for token in doc if token.text in observations]\n",
    "\n",
    "    # Align HMM tags and SpaCy tags\n",
    "    common_len = min(len(spacy_tags), len(tags))\n",
    "    aligned_spacy = spacy_tags[:common_len]\n",
    "    aligned_hmm = tags[:common_len]\n",
    "\n",
    "    # Display confusion matrix\n",
    "    cm = confusion_matrix(aligned_spacy, aligned_hmm, labels=list(set(aligned_spacy + aligned_hmm)))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(set(aligned_spacy + aligned_hmm)))\n",
    "    disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "    plt.title(\"Confusion Matrix: SpaCy vs HMM\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except:\n",
    "    print(\"[Optional] To compare with SpaCy, install it and run: python -m spacy download es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c093c9e9",
   "metadata": {},
   "source": [
    "### 3. Embeddings con CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dff2fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions after training: [[0.09581334]\n",
      " [0.91580613]\n",
      " [0.91080945]\n",
      " [0.09593608]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calcula la función de activación sigmoide.\n",
    "\n",
    "    Args:\n",
    "        x (float or np.ndarray): Valor de entrada.\n",
    "\n",
    "    Returns:\n",
    "        float or np.ndarray: Valor transformado por la función sigmoide.\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    \"\"\"\n",
    "    Calcula la derivada de la función sigmoide.\n",
    "\n",
    "    Args:\n",
    "        x (float or np.ndarray): Valor de entrada.\n",
    "\n",
    "    Returns:\n",
    "        float or np.ndarray: Derivada de la función sigmoide.\n",
    "    \"\"\"\n",
    "    return x * (1 - x)\n",
    "\n",
    "# XOR dataset\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "np.random.seed(1)\n",
    "W1 = 2 * np.random.random((2, 4)) - 1\n",
    "W2 = 2 * np.random.random((4, 1)) - 1\n",
    "\n",
    "# Training loop with learning rate\n",
    "lr = 0.1\n",
    "for epoch in range(10000):\n",
    "    # Forward pass\n",
    "    L1 = sigmoid(np.dot(X, W1))\n",
    "    L2 = sigmoid(np.dot(L1, W2))\n",
    "\n",
    "    # Backpropagation\n",
    "    error = y - L2\n",
    "    delta2 = error * sigmoid_derivative(L2)\n",
    "    delta1 = delta2.dot(W2.T) * sigmoid_derivative(L1)\n",
    "\n",
    "    # Update weights\n",
    "    W2 += lr * L1.T.dot(delta2)\n",
    "    W1 += lr * X.T.dot(delta1)\n",
    "\n",
    "print(\"Predictions after training:\", sigmoid(np.dot(sigmoid(np.dot(X, W1)), W2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5447edf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 19.3960\n",
      "Epoch 20, Loss: 12.0407\n",
      "Epoch 40, Loss: 8.0762\n",
      "Epoch 60, Loss: 5.7105\n",
      "Epoch 80, Loss: 4.2228\n",
      "Word embeddings for 'cbow': tensor([ 0.4481, -0.0372, -1.1773, -0.3090, -1.1149, -1.0595,  0.2916, -0.3403,\n",
      "        -0.5832, -3.0561], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# --- 4. CBOW MODEL ---\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "text = \"Estamos aprendiendo sobre el modelo cbow y las redes neuronales\"\n",
    "words = text.lower().split()\n",
    "vocab = list(set(words))\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "ix_to_word = {i: word for word, i in word_to_ix.items()}\n",
    "\n",
    "# CBOW context window size = 1\n",
    "data = []\n",
    "for i in range(1, len(words) - 1):\n",
    "    context = [words[i - 1], words[i + 1]]\n",
    "    target = words[i]\n",
    "    data.append((context, target))\n",
    "\n",
    "class CBOW(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementa el modelo Continuous Bag of Words (CBOW) usando PyTorch para aprender embeddings de palabras.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): Tamaño del vocabulario.\n",
    "        embed_dim (int): Dimensión de los embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        \"\"\"\n",
    "        Inicializa las capas del modelo CBOW.\n",
    "\n",
    "        Args:\n",
    "            vocab_size (int): Tamaño del vocabulario.\n",
    "            embed_dim (int): Dimensión de los embeddings.\n",
    "        \"\"\"\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.linear = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, context_idxs):\n",
    "        \"\"\"\n",
    "        Realiza la pasada hacia adelante del modelo CBOW.\n",
    "\n",
    "        Args:\n",
    "            context_idxs (torch.Tensor): Índices de las palabras de contexto.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Predicción de la palabra objetivo.\n",
    "        \"\"\"\n",
    "        embeds = self.embeddings(context_idxs)\n",
    "        context_vec = embeds.mean(dim=0)\n",
    "        out = self.linear(context_vec)\n",
    "        return out\n",
    "\n",
    "model = CBOW(len(vocab), 10)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train\n",
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    for context, target in data:\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "        target_idx = torch.tensor([word_to_ix[target]], dtype=torch.long)\n",
    "\n",
    "        model.zero_grad()\n",
    "        log_probs = model(context_idxs)\n",
    "        loss = loss_fn(log_probs.view(1, -1), target_idx)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Show learned embeddings\n",
    "print(\"Word embeddings for 'cbow':\", model.embeddings.weight[word_to_ix['cbow']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
